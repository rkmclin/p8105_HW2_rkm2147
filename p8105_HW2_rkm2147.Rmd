---
title: "HW2 Data Wrangling"
author: "Ronae McLin rkm2147"
date: "9/21/2020"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

# Problem 1

 Mr. Trash Wheel data

We will be importing the data, and then follow up by cleaning it.

```{r}
trash_df = readxl::read_excel("./trash_wheel.xlsx",                    range = "A2:N408") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )

```

We are next going to read and clean precipitation data for 2017/2018. 

```{r}
rain_2018 = readxl::read_excel("./trash_wheel.xlsx",                    sheet = "2018 Precipitation",
        skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2018) %>% 
        relocate(year)
  
rain_2017 = readxl::read_excel("./trash_wheel.xlsx",                    sheet = "2017 Precipitation",
        skip = 1) %>% 
        janitor::clean_names() %>% 
        drop_na(month) %>% 
        mutate(year = 2017) %>% 
        relocate(year)
```

Next up, changing the variable of month into a complete month name and then combining 2017 and 2018 into one table. 

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)

rain_df = bind_rows(rain_2017, rain_2018)

rain_df =
	left_join(rain_df, month_df, by = "month") %>% 
  select(year, total, month_name) %>% 
  relocate(month_name)
  
```

Summary of Mr. Trash Wheel
```{r}
summary(trash_df)
```

The trash data frame contains information about the Mr.Trash Wheel trash collector that is located in Baltimore, Maryland. The size of the data frame is `r nrow(trash_df)` rows by `r ncol(trash_df)` columns. The total amount of glass bottles collected by Mr. Trash Wheel so far is `r trash_df %>% pull(glass_bottles) %>% sum()` and the total amount of plastic bottles so far is `r trash_df %>% pull(plastic_bottles) %>% sum()`. The median number of sports balls in 2017 was `r trash_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`. The size of the rain data frame is `r nrow(rain_df)` rows by `r ncol(rain_df)` columns. The total amount of precipitation in 2018 was `r rain_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.


# Problem 2

NYC Transit Data!

```{r}
transit_df = read_csv("./transit.csv") %>% janitor::clean_names() %>% 
  select(line, station_name,
         station_latitude,
         station_longitude,
         route1:route11,
         entry,vending,
         entrance_type, ada) %>% 
  
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE")) %>% 
  
  mutate(route8 = as.character(route8)) %>% 
  mutate(route9 = as.character(route9)) %>% 
  mutate(route10 = as.character(route10)) %>% 
  mutate(route11 = as.character(route11)) %>% 
   
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    values_to = "route_number"
  )
    
```

```{r}
summary(transit_df)
```

The transit dataset contains a total of `r nrow(transit_df)` variables.  More specifically the variables:`r names(transit_df)`. In my opinion this data is not very tidy!  Cleaning of the data so far consisted of dropping tangential variables, cleaning up variable names using the janitor tool, and changing entry into a logical variable. I also used the pivot tool to condense the routes listed.  The size of the resulting data set is `r nrow(transit_df)` rows by `r ncol(transit_df)` columns. 

- There are `r count(distinct(transit_df, line, station_name))` distinct stations within the NYC transit. 

- There are a total of `r filter(transit_df,ada == "TRUE") %>% distinct(line, station_name) %>% count ()` distinct stations that are ADA compliant. 

- There are a total of `r filter(transit_df,route_number == "A") %>% distinct(line, station_name) %>% count ()` distinct stations that serve the A train. 

- The proportion of station entrances / exits without vending that allow entrance is `r filter(transit_df,vending == "NO") %>%count()/filter(transit_df,entry == "TRUE") %>%count()`.

- There are a total of `r filter(transit_df,route_number == "A") %>% filter(ada == "TRUE") %>% distinct(line, station_name) %>% count ()` distinct stations that serve the A train that are ADA compliant. 



# Problem 3


Creating a Final 538 dataset from three sources of information!

 Importing and tidying of pols data

```{r pols}
pols_df = read_csv("./538_data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year","month","day"))

polsmonth_df = 
	tibble(
		month = c("01","02","03","04","05","06","07","08","09","10","11","12"),
		month_name = month.name
	)

pols_df =
	left_join(pols_df, polsmonth_df, by = "month") %>% 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem",
      prez_gop == 2 ~ "gop",
      )) %>% 

select(year, gov_gop, sen_gop, rep_gop, gov_dem, rep_dem, sen_dem, month_name, president) %>% 
  relocate(year, month_name)

```

Importing and tidying of the snp data
```{r snp}
snp_df = read_csv("./538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month","day","year"))

snpmonth_df = 
	tibble(
		month = c("1","2","3","4","5","6","7","8","9","10","11","12"),
		month_name = month.name
	)

snp_df =
	left_join(snp_df, snpmonth_df, by = "month") %>% 
  select(year, close, month_name) %>% 
  relocate(year, month_name)
```

Importing and tidying of the unemployment data
```{r unemployment}
unemployment_df = read_csv("./538_data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percentage"
  )

unmonth_df =
  tibble(
    month = c("jan","feb","mar","apr","may","jun","jul","aug","sep","oct","nov","dec"),
    month_name = month.name
    )

unemployment_df =
	left_join(unemployment_df, unmonth_df, by = "month") %>% 
  select(year, month_name, percentage)
```

Need to merge the three resulting datasets into one using month and year.

```{r}

final538_df = left_join(pols_df, snp_df, by = c("year","month_name")) %>% 
  mutate(year = as.integer(year))

final538_df = left_join(final538_df, unemployment_df, by = c("year","month_name"))

```

Final 538 data
```{r final538}
summary(final538_df)
```

The Final 538 dataset combines three data frames containing information regarding unemployment percentages, national politicians who are democratic or republican, and the closing values of the S&P stock index. The resulting size of this frame is `r nrow(final538_df)` rows x `r ncol(final538_df)` columns. Variables within this set include: `r names(final538_df)`. Notable variables including "year", "president", "close", and "percentage".  The information spans between the years `r final538_df %>% pull(year) %>% range()`.  Fun fact, in the year 2001 the average unemployment percentage was `r final538_df %>% filter(year == 2001) %>% pull(percentage) %>% mean()`. Interestingly so, in the year of 1974, there were 2 `r final538_df %>% filter(year == 1974) %>% pull(president) %>% max()` presidents. The most recent mean of the closing values for the S&P stock index was `r final538_df %>% filter(year == 2015) %>% pull(close) %>% mean()`.